<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[docker命令]]></title>
    <url>%2F2018%2F06%2F17%2Fdocker%2Fdokcer%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[前言docker在实际的开发、学习以及线上部署中已经频繁被用到，这里总结了一些常用的docker命令，以及docker使用过程中遇到的一些坑，记录爬坑的过程。以便再次遇到相同问题的时候查阅。 删除所有容器1docker rm $(docker ps -aq) 条件查询容器 根据状态查询容器查询条件如下： 例如： 1docker ps -f "status=created" 快速删除退出的容器1docker rm $(docker ps -q -f "status=exited") nginx镜像的日志123# forward request and error logs to docker log collectorRUN ln -sf /dev/stdout /var/log/nginx/access.log \ &amp;&amp; ln -sf /dev/stderr /var/log/nginx/error.log 官方dockerfile中有以上的命令，即将日志输出到标准输出和标准错误输出 在宿主机可以使用docker logs命令查看日志 1docker logs -f containerId 镜像占用硬件状态1docker stats containerId]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[压力测试工具webbench安装与使用]]></title>
    <url>%2F2018%2F06%2F16%2F%E6%9E%B6%E6%9E%84%2F%E5%8E%8B%E5%8A%9B%E6%B5%8B%E8%AF%95%E5%B7%A5%E5%85%B7webbench%E5%8E%8B%E6%B5%8Bnginx%2F</url>
    <content type="text"><![CDATA[Webbench能测试处在相同硬件上，不同服务的性能以及不同硬件上同一个服务的运行状况。webbench的标准测试可以向我们展示服务器的两项内容：每秒钟相应请求数和每秒钟传输数据量。webbench不但能具有便准静态页面的测试能力，还能对动态页面（ASP,PHP,JAVA,CGI）进 行测试的能力。还有就是他支持对含有SSL的安全网站例如电子商务网站进行静态或动态的性能测试。 **Webbench最多可以模拟3万个并发连接去测试网站的负载能力。 安装1234wget http://www.ha97.com/code/webbench-1.5.tar.gztar zxvf webbench-1.5.tar.gzcd webbench-1.5make &amp;&amp; make install 报错12345678910111213cc -Wall -ggdb -W -O -c -o webbench.o webbench.cwebbench.c: 在函数‘alarm_handler’中:webbench.c:77:31: 警告：未使用的参数‘signal’ [-Wunused-parameter] static void alarm_handler(int signal) ^cc -Wall -ggdb -W -O -o webbench webbench.octags *.c/bin/sh: ctags: 未找到命令make: [tags] 错误 127 (忽略)install -s webbench /usr/local/bininstall -m 644 webbench.1 /usr/local/man/man1install: 无法创建普通文件&quot;/usr/local/man/man1&quot;: 没有那个文件或目录make: *** [install] 错误 1 这是因为缺少ctags,需要安装依赖，centos7环境下直接yum安装； 1yum install ctags 再次执行make &amp;&amp; make install,依旧报错 12345ctags *.cinstall -s webbench /usr/local/bininstall -m 644 webbench.1 /usr/local/man/man1install: 无法创建普通文件&quot;/usr/local/man/man1&quot;: 没有那个文件或目录make: *** [install] 错误 1 这是因为没有指定的目录导致的，通过mkdir创建指定的目录即可，再次make &amp;&amp; make install 得到安装成功结果 12345install -s webbench /usr/local/bininstall -m 644 webbench.1 /usr/local/man/man1install -d /usr/local/share/doc/webbenchinstall -m 644 debian/copyright /usr/local/share/doc/webbenchinstall -m 644 debian/changelog /usr/local/share/doc/webbench 使用命令提示 12345678910111213141516webbenchwebbench [option]... URL -f|--force Don&apos;t wait for reply from server. -r|--reload Send reload request - Pragma: no-cache. -t|--time &lt;sec&gt; Run benchmark for &lt;sec&gt; seconds. Default 30. -p|--proxy &lt;server:port&gt; Use proxy server for request. -c|--clients &lt;n&gt; Run &lt;n&gt; HTTP clients at once. Default one. -9|--http09 Use HTTP/0.9 style requests. -1|--http10 Use HTTP/1.0 protocol. -2|--http11 Use HTTP/1.1 protocol. --get Use GET request method. --head Use HEAD request method. --options Use OPTIONS request method. --trace Use TRACE request method. -?|-h|--help This information. -V|--version Display program version. 示例1webbench -c 500 -t 10 localhost/test 每次500个客户端，访问10s nginx配置根据机器的硬件配置 1234567worker_processes 1;events &#123; worker_connections 1024;&#125; 结果如下： 十秒内完成了接近六万的请求，每秒差不多六千并发；可以多试几次 将客户端数量进行调整，测试得到如下结果 客户端个数 请求时间(s) requests(susceed) 平均每秒请求个数（requests/sec） 500 10 58310 5831 1000 10 60899 6090 2000 10 84720 8472 5000 10 85271 8527 当客户端个数调整到10000的时候，已经可以看到，已经访问不到资源 调整机器配置和nginx配置将cpu调整到4核，内存调到2048 nginx配置调整如下 1234567worker_processes 4;events &#123; worker_connections 1024;&#125; 客户端个数 请求时间(s) requests(susceed) 平均每秒请求个数（requests/sec） 500 10 164548 16454 1000 10 198593 19859 2000 10 190463 19046 5000 10 182662 182662 10000 10 161927 16192 可以看见，最大的并发为19859，可见传言nginx每秒两万并发并非空穴来风，和论坛里大家的一万八也不相上下，当然这里的请求都是最简单的静态资源请求，没有特别复杂的业务。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>webbench</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用scrapy+scrapy-splash爬取网易云音乐歌单]]></title>
    <url>%2F2018%2F05%2F02%2Fpython%2Fscrapy%2F</url>
    <content type="text"><![CDATA[创建项目123scrapy startproject music163Scrapycd music163Scrapyscrapy genspider Music163 163.com 文件目录如下： Items.py生成项目目录之后就可以开始编写代码啦，首先修改items.py，定义我们爬取网页后收集的字段。 1234567891011121314import scrapyclass Scrapymusic163Item(scrapy.Item): # define the fields for your item here like: # name = scrapy.Field() title = scrapy.Field() # 标题 link = scrapy.Field() # 链接 realLink=scrapy.Field() #完整连接 desc = scrapy.Field() # 简述 listenCount = scrapy.Field() #播放数量 posttime = scrapy.Field() # 发布时间 imgUrl=scrapy.Field() # 歌单封面图片url # pass Music163Spider123456789101112131415161718192021222324252627282930313233343536373839404142434445class Music163Spider(scrapy.Spider): name = "music163" allowed_domains = ["163.com"] start_urls = [ "https://music.163.com/discover/playlist/?order=new", "https://music.163.com/#/discover/playlist/" ] def parse(self, response): for url in self.start_urls: yield SplashRequest(url=url, callback=self.parseRequest,endpoint='render.json', args=&#123;'wait': 1,'html':1,'iframes': 1,'script':1&#125;) def parseRequest(self,response): iframe_html = response.data['childFrames'][0]['html'] sel = parsel.Selector(iframe_html) # for se in sel.xpath('//div[@class="n-rcmd"]/div[@class="v-hd2"]/div[@class="tab"]/a'): for se in sel.xpath("//div[@id='cateListBox']/div[@class='bd']//a")[1:]: item = Scrapymusic163Item() item['title'] = se.xpath('text()')[0].extract() item['link'] = se.xpath('@href')[0].extract() url = response.urljoin(item['link']) yield SplashRequest(url,self.parse_gedan,endpoint='render.json', args=&#123;'wait': 2,'html':1,'iframes': 1,'script':1&#125;) def parse_gedan(self, response): iframe_html = response.data['childFrames'][0]['html'] sel = parsel.Selector(iframe_html) for se in sel.xpath('//ul[@id="m-pl-container"]/li'): item = Scrapymusic163Item() item['title'] = se.xpath('p[@class="dec"]/a/text()')[0].extract() item['link'] = se.xpath('p[@class="dec"]/a/@href')[0].extract() url=response.urljoin(item['link']) item['realLink']=url item['listenCount']=se.xpath('div/div/span[@class="nb"]/text()')[0].extract() if(item['listenCount'] and "万" in item['listenCount']): item['listenCount']=int(item['listenCount'].replace("万","0000")) item['listenCount']=int(item['listenCount']) item['imgUrl']=se.xpath('div/img[@class="j-flag"]/@src')[0].extract() yield item next_pages = sel.xpath('//a[@class="zbtn znxt"]') if next_pages: url = response.urljoin(next_pages.xpath('@href')[0].extract()) yield SplashRequest(url,self.parse_gedan,endpoint='render.json', args=&#123;'wait': 2,'html':1,'iframes': 1,'script':1&#125;)if __name__ == '__main__': pass 上边这段代码是爬取歌单的关键。这里首先说下爬取的思路，打开网易云的网站，找到歌单连接,歌单分为热门和最新两种，每种又根据风格分为72小类，思路就是先爬取所有种类的连接 再打开每类歌单的网页 从上面的图片中，我们可以看到每首歌的标题,连接，收听次数等信息。 scrapy-splash由于网易云的连接嵌套了动态链接的iframe,这里使用了scrapy-splash来动态渲染iframe，相当于让scrapy-splash来执行网页中的js，并将渲染结果返给我们，这样我们就可以继续使用xpath来筛选自己感兴趣的内容了。 docker 部署scrapy-splash123docer pull scrapinghub/splashdocker run -p 8050:8050 scrapinghub/splash 配置1vim setting.py 1234567891011121314151617#SPLASH SERVERSPLASH_URL = 'http://127.0.0.1:8050/render.json'DOWNLOADER_MIDDLEWARES = &#123; 'scrapy_splash.SplashCookiesMiddleware': 723, 'scrapy_splash.SplashMiddleware': 725, 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware': 810,&#125;SPIDER_MIDDLEWARES = &#123; 'scrapy_splash.SplashDeduplicateArgsMiddleware': 100,&#125;DUPEFILTER_CLASS = 'scrapy_splash.SplashAwareDupeFilter'HTTPCACHE_STORAGE = 'scrapy_splash.SplashAwareFSCacheStorage' 详细参见scrapy-splash文档 需要注意的是在使用scrapy-splash时需要用SplashRequest来代替scrapy原始的request,这是scrapy-splash对scrapy的request进行了进一步的封装，支持了更多的参数，同时也支持将request的返回配置为不同的格式，如html,json等。这里使用了json返回。 mongodb依赖scrapy-mongodb 1234567891011ITEM_PIPELINES = &#123; "scrapy_mongodb.MongoDBPipeline":900&#125;MONGODB_URI = 'mongodb://root:'+urllib.parse.quote('MyNewPass+@321')+'@localhost:27017'MONGODB_DATABASE = 'scrapy'# MONGODB_COLLECTION = 'my_items'# 连接不重复，避免重复爬取MONGODB_UNIQUE_KEY = 'realLink'MONGODB_SEPARATE_COLLECTIONS = True 爬取结果 共爬取了15万左右的歌单。下面是播放次数最多的五个歌单 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849/* 1 */&#123; "_id" : ObjectId("5aea7a036d5b76bf8d42659d"), "title" : "华语速爆新歌", "link" : "/playlist?id=924680166", "realLink" : "https://music.163.com/playlist?id=924680166", "listenCount" : 152900000, "imgUrl" : "http://p1.music.126.net/Zcv4NgK5T0bd1yMzAFp8Iw==/109951163276364917.jpg?param=140y140"&#125;/* 2 */&#123; "_id" : ObjectId("5aea78a56d5b76bf8d422179"), "title" : "【节奏控】那些超带感的音乐（典藏版）", "link" : "/playlist?id=306397077", "realLink" : "https://music.163.com/playlist?id=306397077", "listenCount" : 140930000, "imgUrl" : "http://p1.music.126.net/RnOZHM0BNxXuy-RwQQI5BA==/3313928048221849.jpg?param=140y140"&#125;/* 3 */&#123; "_id" : ObjectId("5aea7fd16d5b76bf8d43b0db"), "title" : "【旋律控】超级好听的外文歌", "link" : "/playlist?id=310970433", "realLink" : "https://music.163.com/playlist?id=310970433", "listenCount" : 101740000, "imgUrl" : "http://p1.music.126.net/2MsstS-M9w5-li0aRy3sUQ==/1380986606815861.jpg?param=140y140"&#125;/* 4 */&#123; "_id" : ObjectId("5aea95f76d5b76bf8d46289a"), "title" : "那些只听前奏就中毒的英文歌", "link" : "/playlist?id=37432514", "realLink" : "https://music.163.com/playlist?id=37432514", "listenCount" : 95420000, "imgUrl" : "http://p1.music.126.net/mQy3lRj6YJ0TW3fM9v85YA==/6643249256145165.jpg?param=140y140"&#125;/* 5 */&#123; "_id" : ObjectId("5aea789a6d5b76bf8d42194c"), "title" : "【欧美男团】秒杀耳朵系列", "link" : "/playlist?id=117377955", "realLink" : "https://music.163.com/playlist?id=117377955", "listenCount" : 71150000, "imgUrl" : "http://p1.music.126.net/FJAxNkFoq3dGiS9tz_bGgQ==/3405187512421439.jpg?param=140y140"&#125; github地址https://github.com/tracerZzz/music163Scrapy 参考 scrapy文档 scrapy-splash文档 scrapy-mongodb]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>scrapy</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git常用命令]]></title>
    <url>%2F2018%2F04%2F15%2Fgit%2Fgit%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[放弃修改git checkout filename 放弃某个文件修改 git checkout . &amp;&amp; git clean -df 放弃当前目录所有文件的修改 查看提交记录git log 回滚git reset –hard a2d36837308dcb2f53687abbc43b88096ee39d91 返回到某个节点，不保留修改。 当本地使用reset进行代码回滚的时候，在往远程push的时候需要使用-f 参数 当前状态git status 推送到远程git push -f origin master 合并分支git merge upstream/master git 配置—local 为当前项目的配置 —global为全局的配置 git config —local user.name “tracerzzz” git config —local user.email “173439618@qq.com”]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[通过keepalived搭建Mysql、zabbix双主模式的高可用集群系统]]></title>
    <url>%2F2018%2F03%2F23%2F%E6%9E%B6%E6%9E%84%2F%E9%80%9A%E8%BF%87keepalived%E6%90%AD%E5%BB%BAmysql%E5%8F%8C%E4%B8%BB%E6%A8%A1%E5%BC%8F%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%E7%B3%BB%E7%BB%9F%2F</url>
    <content type="text"><![CDATA[Mysql双主模式mysql双主模式也叫做主主同步或者双主互备，即两台数据库server互为主备。双主模式是在普通的master-slave主备模式下进一步拓展而来的，普通的master-slave主备模式即一主一备，slave主机拉取master主机的Binary log，然后将二进制文件解析为sql语句并完全顺序的执行sql语句所记录的所有操作，从而使slave的数据和master保持一致；双主互备是两台机器互相以对方为master，定时拉取对方的Binary log。双主互备中两台主机都可以进行读写操作，而在普通主备，只有master可以进行写操作，slave只能进行读取操作； KeepalivedKeepalived是一款高可用软件。keepalived可以让服务器集群共享一个虚拟ip，也就是我们说的vip，同一时间只有一个服务器占有这个虚拟ip，若该服务器不可用或者该服务器的权重小于其他机器，则虚拟IP漂移至另一台服务器并对外提供服务； 准备工作机器准备（centos7系统）两台server:183.57.148.5（master）,183.57.148.7(slave) 一个vip:183.57.148.23 由于基于vrrp协议，两台server和vip必须处于同一网段 安装mysql 并初始化密码首先登陆master 12yum install mysql-servermysql -h localhost -u root -p 发现需要输入密码,于是去日志文件里找默认密码 1vim /var/log/mysql.log 找到下面一行 [Note] A temporary password is generated for root@localhost: i8nk2b*1z,bS i8nk2b*1z,bS是初始化的密码，再次使用mysql -h localhost -u root -p登陆 使用以下命令重置root密码 1ALTER USER 'root'@'localhost' IDENTIFIED BY 'MyNewPass111!'; 登陆slave执行相同的操作 下载zabbix-proxy，导入表结构1yum install zabbix-proxy-mysql 然后根据zabbix文档提示创建数据库表结构 1mysql -h localhost -u root -p 1create database zabbix_proxy character set utf8 collate utf8_bin; 为zabbix_proxy库创建zabbix用户并授权，然后退出（避免使用root登陆特定的数据库） 12grant all privileges on zabbix_proxy.* to zabbix@localhost identified by 'Zabbix@ctzcdn4321!'; quit 执行zabbix_proxy自带的sql生成zabbix_proxy表结构 1zcat /usr/share/doc/zabbix-proxy-mysql-3.4.1/schema.sql.gz |mysql -uroot -p zabbix_proxy 这个过程需要耐心等待一会，然后登陆数据库查看表数量 一共140个，如果数量不对，需要drop掉zabbix_proxy重新再生成一次。 最后在slave机器上也执行以上操作。确保两台机器的数据库表结构一致； 修改/etc/my.cnf文件，配置同步1vim /etc/my.cnf 在[mysqld]下追加 1234567891011121314151617log-bin = mysql-bin #开启binlog日志binlog_format = mixed #基于混合模式,mysql Replication 有三种模式，基于语句，基于行，基于混合模式server-id = 1 #server-id master要和slave区分开，master为1 ，slave为2 relay-log = relay-bin # 开启中继日志relay-log-index = slave-relay-bin.index #中继日志的索引文件auto-increment-increment = 2 #主键自增的幅度，这个要和机器的数量一致auto-increment-offset = 1 #从几开始自增，master从1开始自增，每次增加2,即master生成的主键永远为奇数replicate-wild-do-table=zabbix_proxy.% #需要同步的表，这里是zabbix_proxy下的所有的表,用通配符%表示slave_skip_errors = 1062,1032,1060 #同步时跳过的错误编号，1062，1032，1060 重启mysqlsudo systemctl restart mysqld 重新登陆mysql,为slave机器授予replication权限 1grant replication slave on *.* to 'repl_user'@'183.57.148.7' identified by 'MyNewPass111!'; 查看master当前binlog状态信息 1show master status; 在slaver机器上指定数据库master为183.57.148.5，并指定日志文件名字和位置，这样slaver就知道从哪里开始进行同步了。 1change master to master_host='183.57.148.5',master_user='repl_user',master_password='MyNewPass111!',master_log_file='mysql-bin.000001', master_log_pos=154; 开启slaver 1start slave 接下来在slave机器上进行同样的操作，给maser授予复制权限，然后查看slave机器的binlog状态信息（每个机器的不一定一样，这里和maser的状态一样） 1grant replication slave on *.* to &apos;repl_user&apos;@&apos;183.57.148.4&apos; identified by &apos;MyNewPass111!&apos;; 在master机器上指定数据库master为183.57.148.7,并指定日志文件名字和位置 1change master to master_host='183.57.148.7',master_user='repl_user',master_password='MyNewPass111!',master_log_file='mysql-bin.000001', master_log_pos=154; 开启slaver 1start slave 防火墙设置开启3306端口 123sudo firewall-cmd --zone=public --add-port=3306/tcp --permanentsudo firewall-cmd --reload 验证数据库同步在两台机器上分别查看slave状态 1show slave status\G; 必须确保两个参数 Slave_IO_Running，Slave_SQL_Running为Yes 都为yes后创建一个表，测试同步数据 1234567DROP TABLE IF EXISTS `test`;CREATE TABLE `test` ( `id` int(11) NOT NULL AUTO_INCREMENT, PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=utf8;insert test values();select * from test; 在master机器上执行上面的操作,返回结构， 在slave上也执行查询语句select * from test;,返回同样的结果。再在master上执行insert test values();返回结果如下 可以看到master上的所有自增主键都是奇数，接着在slave机器上执行insert test values();语句，结果为123，slave为偶数，从2开始，说明我们的自增配置已经生效，并且也进行了数据同步； 下载安装keepalivedyum install keepalived下载keepalived，keepalived只有一个配置文件，默认位于/etc/keepalived/keepalived.conf 在配置之前先查看本地机器的网卡设置，使用ip a命令,得知当前ip使用的是网卡eth0,这个要根据ip a命令执行结果得到。网卡名称将在接下来的keepalived配置文件和防火墙设置中用到。 1vim /etc/keepalived/keepalived.conf 1234567891011121314151617181920212223242526272829303132333435! Configuration File for keepalivedglobal_defs &#123; router_id mysql-1&#125;#group vrrp_sync_group VG1 &#123; group &#123; HA_1 &#125; &#125;vrrp_script check_mysql &#123;script /etc/keepalived/bin/check.shinterval 2 #执行间隔weight 20 #权重&#125;vrrp_instance HA_1 &#123; state BACKUP #两个节点最好都设置成BACKUP模式，避免因为意外情况下（比如脑裂）相互抢占导致往两个节点写入相同数据而引发冲突； interface eth0 #网卡 virtual_router_id 51 #两台机器要一致 priority 100 #初始权重，master机器配置为100，slave配置为90 nopreempt #不抢占，当slave机器正常工作时，master恢复正常后不抢占slave的vip advert_int 1 #检查间隔，两台机器一致 authentication &#123; auth_type PASS auth_pass 1111 #两台一致 &#125; virtual_ipaddress &#123; 183.57.148.23 #vip &#125; track_script &#123; check_mysql &#125;&#125; keepalived的配置文件说明vrrp_sync_group的应用场景为：如果路由有2个网段，一个内网，一个外网，每个网段开启一个VRRP实例，假设VRRP配置为检查内网，那么当外网出现问题 时，VRRPD会认为自己是健康的，则不会发送Master和Backup的切换，从而导致问题，Sync Group可以把两个实例都放入Sync Group，这样的话，Group 里任何一个实例出现问题都会发生切换。在这里其实并没有用到group，因为我们只设置了一个实例。 vrrp_instance配置了检测脚本，vip等信息。两台机器的配置基本一致，除了priority参数（master设置为100，slave设置为90）。当master机器keepalivde启动后，将会去执行check.sh，每两秒执行一次，如果执行结果返回零，将在初始权重上加上20，maste的权重将达到120，同理，slave的权重为110（90+20）。这时，vip将漂移到master机器上。如果master上的check.sh执行结果返回1,那么master的权重将不会加20，那么master的权重为100，小于110，此时vip将漂移到slave机器上。keepalived就是这样根据权重的大小进行vip漂移的。另外，需要注意的是，检测脚本的权重一定要大于两台机器的初始权重，20&gt;(100-90),因为只有这样，检测脚本检测到服务异常时才能影响到权重的总和。 vrrp_script配置了检测脚本和被检测的服务的权重，以及检测频率等。这里的关键是check.sh的实现。这个脚本这里主要是用来检测mysql是否正常服务，而正常服务的检测可以很简单，也可以很复杂，比如简单的检测msyqld服务是否正常启动，复杂的可以用msyl命令登陆数据库，执行sql语句，查看mysql的状态，进行判断。这里我们只是简单的检测了mysqld服务是否正常启动； 12#!/bin/bashkillall -0 mysqld zabbix_proxy 试了了killall命令，如果没有该命令需要安装sudo yum install psmisc -y,-0 是检测服务正常运行的信号量，如果正常运行返回0，不正常返回1，支持传入多个服务； 同时需要注意的是记得为该脚本授权chmod +x /etc/keepalived/bin/check.sh; sudo vim check.sh 12#!/bin/bashsudo killall -0 mysqld zabbix-proxy Keepalived防火墙设置keepalived需要执行下面两条语句，对防火墙进行操作，才能确保两台keepalived能够进行选举,如果没有进行防火墙设置，则会出现两台机器都绑定了vip（脑裂）,原因就是两台机器没法进行通信，无法找到真正的master; 123sudo firewall-cmd --direct --permanent --add-rule ipv4 filter INPUT 0 --in-interface eth0 --destination 224.0.0.18 --protocol vrrp -j ACCEPTsudo firewall-cmd --direct --permanent --add-rule ipv4 filter OUT 0 --out-interface eth0 --destination 224.0.0.18 --protocol vrrp -j ACCEPTsudo firewall-cmd --reload 启动zabbi-proxy修改配置文件vim /etc/zabbix/zabbix_proxy.conf 123456789101112131415161718192021222324252627ProxyMode=1Server=124.126.126.143Hostname=183.57.148.23 #vipLogFile=/var/log/zabbix/zabbix_proxy.logLogFileSize=0PidFile=/var/run/zabbix/zabbix_proxy.pidSocketDir=/var/run/zabbixDBHost=localhostDBName=zabbix_proxyDBUser=zabbixDBPassword=Zabbix@ctzcdn4321!HeartbeatFrequency=10ConfigFrequency=60DataSenderFrequency=5StartPollers=50StartPollersUnreachable=10StartTrappers=10StartPingers=10SNMPTrapperFile=/var/log/snmptrap/snmptrap.logCacheSize=8GStartDBSyncers=10HistoryCacheSize=2GHistoryIndexCacheSize=2GTimeout=30#DebugLevel=4#ExternalScripts=/usr/lib/zabbix/externalscripts#LogSlowQueries=3000 12345#开启端口sudo firewall-cmd --zone=public --add-port=10051/tcp --permanentsudo firewall-cmd --reload#启动zabbix-proxysystemctl start zabbix-proxy 开机自动启动12systemctl enable zabbix-proxysystemctl enable mysqld 测试方法1.查看vip绑定情况 ip a 2.通过连接vip的mysql， 12msyql -h 183.57.148.23 -uroot -pshow variables like &quot;%hostname%&quot;; 查看返回的hostaname,就知道了当前连接是哪台机器 MySQL出现同步延迟解决优化方法1.主从复制的从库太多导致复制延迟优化：建议从库数量3-5个为宜（具体看自己硬件配置） 2.从库硬件比主库硬件差优化：提升硬件性能 3.慢SQL语句过多优化：SQL语句执行时间太长，需要优化SQL语句（需要联系DBA开发共同商讨优化语句） 4.主从复制的设计问题优化：主从复制单线程，可以通过多线程IO方案解决；另外MySQL5.6.3支持多线程IO复制。 5.主从库之间的网络延迟优化：尽量链路短，提升端口带宽 6.主库读写压力大优化：前端加buffer和缓存。主从延迟不同步（延迟的多少，只要不影响业务就没事） 7、业务设计缺陷导致延迟影响业务优化：从库没有数据改读主库]]></content>
      <categories>
        <category>架构</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>keepalived</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[webpack快速入门]]></title>
    <url>%2F2018%2F03%2F08%2Fjs%2Fwebpack%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[webpack介绍截止目前，webpack已经更新到4.0版本，最新版本已经到了v4.1.1(2018-3-8)；这篇文章关于webpack的所有介绍，将基于webpack 的 v4.1.1版本。详细介绍请参考中文文档以及官方文档 在详细介绍具体的配置项之前，在这里先说下webpack到底是个什么东西，在我们的项目中究竟发挥着什么作用，以及可以为我们带来什么样的方便。 webpack 是一个现代 JavaScript 应用程序的静态模块打包器(module bundler)。当 webpack 处理应用程序时，它会递归地构建一个依赖关系图(dependency graph)，其中包含应用程序需要的每个模块，然后将所有这些模块打包成一个或多个 bundle。 说白了，webpack就是一个项目打包工具，他可以将不同的文件通通打入一个或者多个文件。在这个工程中，webpack可以依赖各种loader对不同类型的的文件，进行进一步的操作。比如webpack依赖babel loader对js文件进行es6 es7转码，让你在使用es6 es7新语法的同时还可以将代码运行在比较古老的浏览器中。他还可以利用不同的plugin进行更多操作，比如利用webpack.optimize.UglifyJsPlugin去除代码中的空格，将文件最小化。等等，webpack可以干的事情非常的多，他在前端项目工程化中已经在扮演着一个大管家的作用。 概念webpack是高度可配置的，而配置的项目也不是随意的，webpack中有四个核心概念 入口(entry) 输出(output) loader 插件(plugins) 整个webpack将围绕这四个主要的概念进行配置。 入口(Entry)entry 对象是用于 webpack 查找启动并构建 bundle。这句话可以理解为入口文件就是我们需要打包的文件，入口文件可以是一个也可以是多个。多个入口文件可以应对多页面应用或者用于抽取公共代码或者公用第三方代码库，用于加快首屏加载速度，模块化代码等。 输出(Output)output 位于对象最顶级键(key)，包括了一组选项，指示 webpack 如何去输出、以及在哪里输出你的「bundle、asset 和其他你所打包或使用 webpack 载入的任何内容」。 Loaderloader 用于对模块的源代码进行转换。loader 可以使你在 import 或”加载”模块时预处理文件。 示例12npm install --save-dev css-loadernpm install --save-dev ts-loader 然后指示 webpack 对每个 .css 使用 css-loader，以及对所有 .ts 文件使用 ts-loader： 12345678module.exports = &#123; module: &#123; rules: [ &#123; test: /\.css$/, use: 'css-loader' &#125;, &#123; test: /\.ts$/, use: 'ts-loader' &#125; ] &#125;&#125;; 常用到的loader(vue开发) vue-loader babel-loader url-loader css-loader less-loader 插件(Plugins)插件是 wepback 的支柱功能。插件在开发环境和生产环境为我们提供了非常多的便利，HtmlWebpackPlugin让我们将js和css文件打包到指定的html文件中，等等，下面列出几个常用的插件。 CopyWebpackPlugin //复制文件到打包后的指定目录 DefinePlugin //全局库 CommonsChunkPlugin //重复代码抽取为公共部分 插件 ProvidePlugin //全局变量定义 HotModuleReplacementPlugin 代码热替换 UglifyJsPlugin 代码丑化 其他配置resolve.alias(别名)resolve里面有一个alias的配置项目，能够让开发者指定一些模块的引用路径。对一些经常要被import或者require的库 12345resolve: &#123; alias: &#123; 'vue$': 'vue/dist/vue.esm.js', '@': resolve('src'), &#125; 在引入模块的时候可以这样写 1import Chart from '@/components/Charts/keyboard' dev-tool source mapping用于压缩代码中的错误定位。将压缩后的代码与source code之间匹配一个索引，当压缩代码某处出错时，精确到索引到源代码中的指定行。 iview-admin中的webpack项目目录结构如下 项目中webpack配置包含在build目录下，共三个，分别为base，dev，product，代表了基本配置，开发环境配置，生产环境配置。dev和product两个文件都使用了merge方法来将base中基础配置和自己的配置进行合并，这里依赖webpack-merge base配置123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114const path = require('path');const os = require('os');const webpack = require('webpack');const ExtractTextPlugin = require('extract-text-webpack-plugin');const HappyPack = require('happypack');var happyThreadPool = HappyPack.ThreadPool(&#123; size: os.cpus().length&#125;);function resolve(dir) &#123; return path.join(__dirname, dir);&#125;module.exports = &#123; entry: &#123; main: '@/main', 'vender-base': '@/vendors/vendors.base.js', 'vender-exten': '@/vendors/vendors.exten.js' &#125;, output: &#123; path: path.resolve(__dirname, '../dist/dist') &#125;, module: &#123; rules: [&#123; test: /\.vue$/, loader: 'vue-loader', options: &#123; loaders: &#123; less: ExtractTextPlugin.extract(&#123; use: ['css-loader?minimize', 'autoprefixer-loader', 'less-loader'], fallback: 'vue-style-loader' &#125;), css: ExtractTextPlugin.extract(&#123; use: ['css-loader', 'autoprefixer-loader'], fallback: 'vue-style-loader' &#125;) &#125; &#125; &#125;, &#123; test: /iview\/.*?js$/, loader: 'babel-loader' &#125;, &#123; test: /\.js$/, loader: 'babel-loader', exclude: /node_modules/ &#125;, &#123; test: /\.js[x]?$/, include: [resolve('src')], exclude: /node_modules/, loader: 'happypack/loader?id=happybabel' &#125;, &#123; test: /\.css$/, use: ExtractTextPlugin.extract(&#123; use: ['css-loader?minimize', 'autoprefixer-loader'], fallback: 'style-loader' &#125;) &#125;, &#123; test: /\.less$/, use: ExtractTextPlugin.extract(&#123; use: ['css-hot-loader', 'autoprefixer-loader', 'less-loader'], fallback: 'style-loader' &#125;), &#125;, &#123; test: /\.(gif|jpg|png|woff|svg|eot|ttf)\??.*$/, loader: 'url-loader?limit=1024' &#125;, &#123; test: /jquery-mousewheel/, loader: "imports-loader?define=&gt;false&amp;this=&gt;window" &#125;, &#123; test: /malihu-custom-scrollbar-plugin/, loader: "imports-loader?define=&gt;false&amp;this=&gt;window" &#125;, &#123; test: /\.(html|tpl)$/, loader: 'html-loader' &#125; ] &#125;, plugins: [ new HappyPack(&#123; id: 'happybabel', loaders: ['babel-loader'], threadPool: happyThreadPool, cache: true, verbose: true &#125;), //全局库 new webpack.ProvidePlugin(&#123; $: 'jquery', jQuery: 'jquery', "window.jQuery": "jquery", //_: "lodash", &#125;), ], resolve: &#123; extensions: ['.js', '.vue'], alias: &#123; 'vue': 'vue/dist/vue.esm.js', '@': resolve('../src'), 'node_modules': resolve('../node_modules'), webworkify: 'webworkify-webpack-dropin' &#125; &#125;&#125;; product配置1234567891011121314151617181920212223new cleanWebpackPlugin(['dist/*'], &#123; root: path.resolve(__dirname, '../') &#125;), new ExtractTextPlugin(&#123; filename: '[name].[hash].css', allChunks: true &#125;), new webpack.optimize.CommonsChunkPlugin(&#123; // name: 'vendors', // filename: 'vendors.[hash].js' name: ['vender-exten', 'vender-base'], minChunks: Infinity &#125;), new webpack.DefinePlugin(&#123; 'process.env': &#123; NODE_ENV: '"production"' &#125; &#125;), new webpack.optimize.cleanWebpackPlugin(&#123; compress: &#123; warnings: false &#125; &#125;), 生产环境每次打包都需要将之前生成的文件清除，这里使用了cleanWebpackPlugin插件。另外在生产环境中要将代码尽量压缩到最小化，这里使用了cleanWebpackPlugin插件。 另外：如果项目使用nginx部署，还可以使用nginx进行压缩]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>webpack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解javaScript笔记-编写高质量JavaScript代码的基本要点]]></title>
    <url>%2F2018%2F01%2F17%2Fjs%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3javaScript%E7%AC%94%E8%AE%B0-%E7%BC%96%E5%86%99%E9%AB%98%E8%B4%A8%E9%87%8FJavaScript%E4%BB%A3%E7%A0%81%E7%9A%84%E5%9F%BA%E6%9C%AC%E8%A6%81%E7%82%B9%2F</url>
    <content type="text"><![CDATA[最小全局变量(Minimizing Globals)JavaScript通过函数管理作用域。在函数内部声明的变量只在这个函数内部，函数外面不可用。 浏览器中的全局变量:this相当于window 1234this.h="hello"//"hello"window.h//"hello" 全局变量的问题全局变量的问题在于，你的JavaScript应用程序和web页面上的所有代码都共享了这些全局变量，他们住在同一个全局命名空间，所以当程序的两个不同部分定义同名但不同作用的全局变量的时候，命名冲突在所难免。 反例一：不声明的任何变量都会成为一个全局对象属性1234567891011//隐式创建全局变量反例1function sum(x, y) &#123; // 不推荐写法: 隐式全局变量 result = x + y; return result;&#125;undefinedsum(1,1)2window.result2 此段代码中的result没有声明。代码照样运作正常，但在调用函数后你最后的结果就是多一个全局变量result。 经验法则是始终使用var声明变量 1234function sum(x, y) &#123; var result = x + y; return result;&#125; 反例二：使用任务链进行部分var声明另一个创建隐式全局变量的反例就是使用任务链进行部分var声明。下面的片段中，a是本地变量但是b确实全局变量，这可能不是你希望发生的： 12345678function foo() &#123; var a = b = 0; // ...&#125;foo()undefined //执行foo()返回undefinedwindow.b //发现b其实为全局变量，倒霉0 此现象发生的原因在于这个从右到左的赋值，首先，是赋值表达式b = 0，此情况下b是未声明的。这个表达式的返回值是0，然后这个0就分配给了通过var定义的这个局部变量a。类似于var a = (b = 0); 先准备好声明变量，再使用链分配是比较好的做法 1234function foo() &#123; var a, b; // ... a = b = 0; // 两个均局部变量&#125; 忘记var的副作用(Side Effects When Forgetting var) 通过var创建的全局变量（任何函数之外的程序中创建）是不能被删除的。 无var创建的隐式全局变量（无视是否在函数中创建）是能被删除的。 隐式全局变量和明确定义的全局变量间有些小的差异，就是通过delete操作符让变量未定义的能力 这表明，在技术上，隐式全局变量并不是真正的全局变量，但它们是全局对象的属性。属性是可以通过delete操作符删除的，而变量是不能的： 12345678910111213141516// 定义三个全局变量var global_var = 1;global_novar = 2; // 反面教材(function () &#123; global_fromfunc = 3; // 反面教材&#125;());// 试图删除delete global_var; // falsedelete global_novar; // truedelete global_fromfunc; // true// 测试该删除typeof global_var; // "number"typeof global_novar; // "global_nar is not defined"typeof global_fromfunc; // "global_fromfunc is not defined" 单var形式（Single var Pattern）在函数顶部使用单var语句是比较有用的一种形式，其好处在于： 提供了一个单一的地方去寻找功能所需要的所有局部变量 防止变量在定义之前使用的逻辑错误 帮助你记住声明的全局变量，因此较少了全局变量//zxx:此处我自己是有点晕乎的… 少代码（类型啊传值啊单线完成） 单var形式长得就像下面这个样子： 123456789function func() &#123; var a = 1, b = 2, sum = a + b, myobject = &#123;&#125;, i, j; // function body...&#125; 变量提升（Hoisting）123456789myname = "global"; // 全局变量,不建议这么写，应该写成 var name = "global"function func() &#123; alert(myname); // "undefined" var myname = "local"; alert(myname); // "local"&#125;func();//alert: undefined//alert: local 上边的代码可以拆分了来理解 12345678myname = "global"; // 全局变量,不建议这么写，应该写成 var name = "global"function func() &#123; var myname=undefined alert(myname); // "undefined" myname = "local"; alert(myname); // "local"&#125;func(); myname变量的声明得到了提升，而在声明的时候是没有被赋值的。在这里还要注意到全局变量和函数内的变量同名，由于js的作用域机制，首先在函数内部找寻找变量，如果没有找到，再去上级（作用域）去找。这里直接找到了，也就不会出现弹出框里显示global的情况。 for循环(for Loops)在for循环中，你可以循环取得数组或是数组类似对象的值，譬如arguments和HTMLCollection对象。 HTMLCollections指的是DOM方法返回的对象，例如： 1234567document.getElementsByName()document.getElementsByClassName()document.getElementsByTagName()document.images: 页面上所有的图片元素document.links : 所有a标签元素document.forms : 所有表单document.forms[0].elements : 页面上第一个表单中的所有域 通常的循环形式如下： 1234// 次佳的循环for (var i = 0; i &lt; myarray.length; i++) &#123; // 使用myarray[i]做点什么&#125; 这种形式的循环的不足在于每次循环的时候数组的长度都要去获取下。这回降低你的代码，尤其当myarray不是数组，而是一个HTMLCollection对象的时候。而DOM操作一般都是比较昂贵的。 这就是为什么当你循环获取值时，缓存数组(或集合)的长度是比较好的形式，正如下面代码显示的： 123for (var i = 0, max = myarray.length; i &lt; max; i++) &#123; // 使用myarray[i]做点什么&#125; for-in循环(for-in Loops)for-in循环应该用在非数组对象的遍历上，使用for-in进行循环也被称为“枚举”。 从技术上将，你可以使用for-in循环数组（因为JavaScript中数组也是对象），但这是不推荐的。因为如果数组对象已被自定义的功能增强，就可能发生逻辑错误。另外，在for-in中，属性列表的顺序（序列）是不能保证的。所以最好数组使用正常的for循环，对象使用for-in循环。 （不）扩展内置原型((Not) Augmenting Built-in Prototypes)扩增构造函数的prototype属性是个很强大的增加功能的方法，但有时候它太强大了 增加内置的构造函数原型（如Object(), Array(), 或Function()）挺诱人的，但是这严重降低了可维护性，因为它让你的代码变得难以预测。使用你代码的其他开发人员很可能更期望使用内置的 JavaScript方法来持续不断地工作，而不是你另加的方法。 另外，属性添加到原型中，可能会导致不使用hasOwnProperty属性时在循环中显示出来，这会造成混乱。 因此，不增加内置原型是最好的。你可以指定一个规则，仅当下面的条件均满足时例外： 可以预期将来的ECMAScript版本或是JavaScript实现将一直将此功能当作内置方法来实现。例如，你可以添加ECMAScript 5中描述的方法，一直到各个浏览器都迎头赶上。这种情况下，你只是提前定义了有用的方法。 如果您检查您的自定义属性或方法已不存在——也许已经在代码的其他地方实现或已经是你支持的浏览器JavaScript引擎部分。 你清楚地文档记录并和团队交流了变化。 如果这三个条件得到满足，你可以给原型进行自定义的添加，形式如下： 12345if (typeof Object.protoype.myMethod !== "function") &#123; Object.protoype.myMethod = function () &#123; // 实现... &#125;;&#125; switch模式(switch Pattern)123456789101112var inspect_me = 0, result = '';switch (inspect_me) &#123;case 0: result = "zero"; break;case 1: result = "one"; break;default: result = "unknown";&#125; 这个简单的例子中所遵循的风格约定如下： 每个case和switch对齐（花括号缩进规则除外） 每个case中代码缩进 每个case以break清除结束 避免贯穿（故意忽略break）。如果你非常确信贯穿是最好的方法，务必记录此情况，因为对于有些阅读人而言，它们可能看起来是错误的。 以default结束switch：确保总有健全的结果，即使无情况匹配。 避免隐式类型转换(Avoiding Implied Typecasting )JavaScript的变量在比较的时候会隐式类型转换。这就是为什么一些诸如：false == 0 或 “” == 0 返回的结果是true。为避免引起混乱的隐含类型转换，在你比较值和表达式类型的时候始终使用===和!==操作符。 123456789var zero = 0;if (zero === false) &#123; // 不执行，因为zero为0, 而不是false&#125;// 反面示例if (zero == false) &#123; // 执行了...&#125; parseInt()下的数值转换(Number Conversions with parseInt())使用parseInt()进行转换时，加上第二个参数，即标明转换进制。 分隔单词(Separating Words)当你的变量或是函数名有多个单词的时候，最好单词的分离遵循统一的规范，有一个常见的做法被称作“驼峰(Camel)命名法”，就是单词小写，每个单词的首字母大写。 对于构造函数，可以使用大驼峰式命名法(upper camel case)，如MyConstructor()。对于函数和方法名称，你可以使用小驼峰式命名法(lower camel case)，像是myFunction(), calculateArea()和getFirstName()。 开发者通常使用小驼峰式命名法，但还有另外一种做法就是所有单词小写以下划线连接：例如，first_name, favorite_bands,和old_company_name，这种标记法帮你直观地区分函数和其他标识——原型和对象。 参考连接：http://www.cnblogs.com/TomXu/archive/2011/12/28/2286877.html]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx使用]]></title>
    <url>%2F2018%2F01%2F15%2Fnginx%2Fnginx%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[nginx手动编译（centos7）1.查看最新稳定版本连接 http://nginx.org/en/download.html 2.wget 最新稳定版 wget http://nginx.org/download/nginx-1.12.2.tar.gz 3.解压文件 1tar zxvf nginx-1.12.2.tar.gz 5.依赖 pcre pcre-devel 1yum -y install pcre.x86_64 &amp;&amp; yum -y install pcre-devel.x86_64 6.依赖 zlib 和zlib-devel 1yum install -y zlib.x86_64 &amp;&amp; yum install -y zlib-devel.x86_64 7.配置 —with-debug 启用debug 1./configure --sbin-path=/usr/local/sbin/ --prefix=/usr/local/nginx --with-debug 增加nginx-rtmp-module 1./configure --sbin-path=/usr/sbin/ --prefix=/usr/local/nginx --add-module=../../nginx-rtmp-module --with-debug 8.make &amp; make install 1make &amp;&amp; make install nginx常用命令 nginx -t 测试配置文件 nginx -s reload 重启 nginx -s quit 退出 nginx -V 查看ngixn安装了哪些模块 gzip配置12345678gzip on;gzip_min_length 1k;gzip_buffers 4 16k;#gzip_http_version 1.0;gzip_comp_level 2;gzip_types text/plain application/x-javascript text/css application/xml application/javascript application/octet-stream text/javascript application/x-httpd-php image/jpeg image/gif image/png;gzip_vary off;gzip_disable "MSIE [1-6]\."; 常用术语UV（Unique visitor） 是指通过互联网访问、浏览这个网页的自然人。访问您网站的一台电脑客户端为一个访客。00:00-24:00内相同的客户端只被计算一次。 一天内同个访客多次访问仅计算一个UV。 IP（Internet Protocol） 独立IP是指访问过某站点的IP总数，以用户的IP地址作为统计依据。00:00-24:00内相同IP地址之被计算一次。 UV与IP区别： 如：你和你的家人用各自的账号在同一台电脑上登录新浪微博，则IP数+1，UV数+2。由于使用的是同一台电脑，所以IP不变，但使用的不同账号，所以UV+2 PV（Page View）即页面浏览量或点击量，用户每1次对网站中的每个网页访问均被记录1个PV。用户对同一页面的多次访问，访问量累计，用以衡量网站用户访问的网页数量。 VV（Visit View）用以统计所有访客1天内访问网站的次数。当访客完成所有浏览并最终关掉该网站的所有页面时便完成了一次访问，同一访客1天内可能有多次访问行为，访问次数累计。 PV与VV区别：如：你今天10点钟打开了百度，访问了它的三个页面；11点钟又打开了百度，访问了它的两个页面，则PV数+5，VV数+2.PV是指页面的浏览次数，VV是指你访问网站的次数。]]></content>
      <categories>
        <category>服务器</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用iterm2自定义命令快速部署hexo博客]]></title>
    <url>%2F2018%2F01%2F14%2Fiterm2%2Fiterm2%E8%87%AA%E5%AE%9A%E4%B9%89%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[环境：iTerm+zsh 12echo "alias hexod='hexo clean &amp;&amp; hexo g &amp;&amp; hexo d'" &gt;&gt; ~/.bash_profilesource ~/.bash_profile 注意双引号中的单引号 在hexo博客目录下执行以下命令 1hexod 以此类推，我们可以在~/.bash_profile文件中添加自定义命令 注意需要注意的是，如果默认是用的zsh的活，每次打开iterm2都要手动的srouce ~/.bash_profile才能生效，比较麻烦 如果你的默认shell是bash ，那么把 1. ~/.bash_profile 追加到 ~/.bashrc 末尾, bash开启时会自动执行.bashrc这个文件 如果是其他的 比如 zsh， 那么追加到 ~/.zshrc 末尾 其他类推。。。]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>iterm2</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[接取送达费率页面实现]]></title>
    <url>%2F2017%2F11%2F02%2FworkRecord%2F</url>
    <content type="text"><![CDATA[页面实现结果如下图： 定义load方法，用来加载费率计算公式，若之前没有设定,创建三条记录，将so,a,b都设置为暂未设定 预加载12345678910111213141516if(!records||records.length==0)&#123; //暂未设定$thisObj.list=[];list=[ &#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_20",containerTypeName:'20英尺集装箱',name:'So',value:'暂未设定',&#125;, &#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_20",value:'暂未设定',name:'A',&#125;, &#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_20",value:'暂未设定',name:'B',&#125;, &#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_40",containerTypeName:'40英尺集装箱',name:'So',value:'暂未设定',&#125;, &#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_40",value:'暂未设定',name:'A',&#125;, &#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_40",value:'暂未设定',name:'B',&#125;, &#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_20",containerTypeName:'20英尺35t箱',name:'So',value:'暂未设定',&#125;, &#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_20",value:'暂未设定',name:'A',&#125;, &#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_20",value:'暂未设定',name:'B',&#125;, ] get('grid').getStore().removeAll(); get('grid').getStore().add(list);&#125; 若果返回的请求结果有设定，那么遍历结果，追加没有的设置 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950else&#123;//已经设定参数$thisObj.list=records; //console.log(1); let items=[]; //grid items for(item of $thisObj.list)&#123; if(item.containerSizeTypeCode=='CONTAINER_SIZE_TYPE_20')&#123; item.containerTypeName='20英尺集装箱'; items.push(&#123;itemId:item.id,containerSizeTypeCode:"CONTAINER_SIZE_TYPE_20",containerTypeName:'20英尺集装箱',name:'So',value:item.initMil,&#125;); items.push(&#123;itemId:item.id,containerSizeTypeCode:"CONTAINER_SIZE_TYPE_20",value:item.initPrice,name:'A'&#125;); items.push(&#123;itemId:item.id,containerSizeTypeCode:"CONTAINER_SIZE_TYPE_20",value:item.milPrice,name:'B'&#125;); &#125; if(item.containerSizeTypeCode=='CONTAINER_SIZE_TYPE_40')&#123; item.containerTypeName='40英尺集装箱'; items.push(&#123;itemId:item.id,containerSizeTypeCode:"CONTAINER_SIZE_TYPE_40",containerTypeName:'40英尺集装箱',name:'So',value:item.initMil,&#125;); items.push(&#123;itemId:item.id,containerSizeTypeCode:"CONTAINER_SIZE_TYPE_40",value:item.initPrice,name:'A'&#125;); items.push(&#123;itemId:item.id,containerSizeTypeCode:"CONTAINER_SIZE_TYPE_40",value:item.milPrice,name:'B'&#125;); &#125; if(item.containerSizeTypeCode=='CONTAINER_SIZE_TYPE_25')&#123; item.containerTypeName='25英尺35t箱'; items.push(&#123;itemId:item.id,containerSizeTypeCode:"CONTAINER_SIZE_TYPE_25",containerTypeName:'25英尺35t箱',name:'So',value:item.initMil,&#125;); items.push(&#123;itemId:item.id,containerSizeTypeCode:"CONTAINER_SIZE_TYPE_25",value:item.initPrice,name:'A'&#125;); items.push(&#123;itemId:item.id,containerSizeTypeCode:"CONTAINER_SIZE_TYPE_25",value:item.milPrice,name:'B'&#125;); &#125; &#125; var count1=0; var count2=0; var count3=0; for(let i of items)&#123; if(i.containerSizeTypeCode&amp;&amp;i.containerSizeTypeCode=='CONTAINER_SIZE_TYPE_20') count1++; if(i.containerSizeTypeCode&amp;&amp;i.containerSizeTypeCode=='CONTAINER_SIZE_TYPE_40') count2++; if(i.containerSizeTypeCode&amp;&amp;i.containerSizeTypeCode=='CONTAINER_SIZE_TYPE_25') count3++; &#125; if(count1==0) &#123; items.push(&#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_20",containerTypeName:'20英尺集装箱',name:'So',value:'暂未设定',&#125;); items.push(&#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_20",value:"暂未设定",name:'A'&#125;); items.push(&#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_20",value:'暂未设定',name:'B'&#125;); &#125; if(count2==0) &#123; items.push(&#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_40",containerTypeName:'40英尺集装箱',name:'So',value:'暂未设定',&#125;); items.push(&#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_40",value:"暂未设定",name:'A'&#125;); items.push(&#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_40",value:'暂未设定',name:'B'&#125;); &#125; if(count3==0) &#123; items.push(&#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_25",containerTypeName:'25英尺35t箱',name:'So',value:'暂未设定',&#125;); items.push(&#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_25",value:"暂未设定",name:'A'&#125;); items.push(&#123;containerSizeTypeCode:"CONTAINER_SIZE_TYPE_25",value:'暂未设定',name:'B'&#125;); &#125; get('grid').getStore().removeAll(); get('grid').getStore().add(items);&#125; 变更费率 校验输入 1234567891011121314151617181920212223var inputValue=[];var inputCount=0;var validflag=0;$("input").each(function()&#123; if($(this).val()==''||$(this).val()==null)&#123; inputCount++; $(this).focus(); &#125;else&#123; var r1= /^[0-9]*[1-9][0-9]*$/ //正整数 if(!r1.exec($(this).val()))&#123; validflag++; &#125; &#125; inputValue.push($(this).val());&#125;);if(inputCount==inputValue.length)&#123; showMsgBox(&#123;text:"请填写一条变更值！" , msgType:'s'&#125;); return;&#125;if(validflag!=0)&#123; showMsgBox(&#123;text:"请输入整数类型！" , msgType:'s'&#125;); return;&#125; 变更费率将数据格式化（将九条记录转换为三条记录），并且如果是首次设定，那么必须三个参数同时填写。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354var gridItem=get('grid').getStore().data.items; var updateList=[]; for(let i=0;i&lt;gridItem.length;i++)&#123; if(gridItem[i].data.containerTypeName)&#123;//存在名称 updateList[parseInt(i/3)]=&#123;&#125;; updateList[parseInt(i/3)].containerTypeName=gridItem[i].data.containerTypeName; updateList[parseInt(i/3)].initMil=gridItem[i].data.value;//so updateList[parseInt(i/3)].initMilBefore=gridItem[i].data.value;//so if(gridItem[i].data.setValue!=''&amp;&amp;gridItem[i].data.setValue!=undefined)&#123; updateList[parseInt(i/3)].initMil=gridItem[i].data.setValue;//so &#125; updateList[parseInt(i/3)].containerSizeTypeCode=gridItem[i].data.containerSizeTypeCode;//so if(gridItem[i].data.itemId)&#123;//存在id updateList[parseInt(i/3)].id=gridItem[i].data.itemId;//so &#125; &#125; if(gridItem[i].data.name=='A')&#123; updateList[parseInt(i/3)].initPrice=gridItem[i].data.value updateList[parseInt(i/3)].initPriceBefore=gridItem[i].data.value if(gridItem[i].data.setValue!=''&amp;&amp;gridItem[i].data.setValue!=undefined)&#123; updateList[parseInt(i/3)].initPrice=gridItem[i].data.setValue &#125; &#125; if(gridItem[i].data.name=='B')&#123; updateList[parseInt(i/3)].milPrice=gridItem[i].data.value updateList[parseInt(i/3)].milPriceBefore=gridItem[i].data.value if(gridItem[i].data.setValue!=''&amp;&amp;gridItem[i].data.setValue!=undefined)&#123; updateList[parseInt(i/3)].milPrice=gridItem[i].data.setValue &#125; &#125; &#125;var removeList=[];for(let item of updateList)&#123; if(!item.id&amp;&amp;item.initMilBefore=="暂未设定"&amp;&amp;item.milPriceBefore=='暂未设定'&amp;&amp;item.initPriceBefore=='暂未设定')&#123;//若之前未设定 var count=0; if(item.initMil=="暂未设定")count++; if(item.milPrice=="暂未设定")count++; if(item.initPrice=="暂未设定")count++; if(count!=0&amp;&amp;count!=3)&#123; showMsgBox(&#123;text:"由于之前"+item.containerTypeName+'未进行计费公式设定，请填写完整数值（so,A,B）! ' , msgType:'s',timer:7000&#125;); return; &#125; if(count==3)&#123; removeList.push(item); &#125; &#125;&#125;for(item of removeList)&#123; updateList.remove(item);&#125;$thisObj.updatelist=updateList; 总结 grid追加输入框 123renderer: function (value, meta, record, rowIndex, colIndex) &#123; return '&lt;input type="text" value="" onchange="var s = Ext.getCmp(\'grid\').store; s.getAt(s.findExact(\'id\',\'' + record.get('id') + '\')).set(\'setValue\', this.value)" /&gt;'; &#125;&#125; 加载完页面调用预加载函数 123listeners:&#123; 'afterrender':load&#125; 请求参数为json格式(1.修改header,2.格式化请求参数-JSON.stringify()) 123456789101112131415var headers=&#123;'Content-Type':'application/json'&#125;; var params=&#123;&#125;; params.receiveFees=$thisObj.updatelist; params=JSON.stringify(params); Ajax.request(&#123; url:basePath + '/receive_fee/update', hide:true, headers: headers, params:params, execute: function (result , success) &#123; changeWindow.hide(); showMsgBox(&#123;text:"变更成功！" , msgType:'s'&#125;); load(); &#125; &#125;) 后台接收方法 123456789101112@RequestMapping("/update")public @ResponseBody ResultBean update(@RequestBody Map&lt;String,Object&gt; params)&#123; //List&lt;ReceiveFee&gt; receiveFees ResultBean resultBean = null; try &#123; List&lt;ReceiveFee&gt; receiveFees = BaseConvertUtil.mapToBean((List&lt;Map&lt;String,Object&gt;&gt;)params.get("receiveFees"),ReceiveFee.class); resultBean = this.receiveFeeService.update(receiveFees); &#125; catch (ServiceException e) &#123; resultBean = BaseResultBeanUtil.getResultBean(e); &#125; return resultBean;&#125;]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>js</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[github 和 gitlab 同时使用]]></title>
    <url>%2F2017%2F07%2F12%2Fgit%2Fgitlab%E5%92%8Cgithub%E5%90%8C%E6%97%B6%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[github 和 gitlab 同时使用 背景：原先电脑上已经存在github配置，公司内部需要使用gitlab进行项目管理，so，需要在同一台机器上配置github和gitlab的账号密码信息 第一步 生成秘钥github设置如下（之前已经设置过了） ssh-keygen -t rsa -C &quot;注册的github邮箱&quot; 提示要输入名称, 不管, 一路回车, 也不要设置密码 接下来配置为gitlab生成秘钥 ssh-keygen -t rsa -C &quot;注册的gitlab邮箱&quot; 这次名称输入id_rsa_gitlab, 路径保存在~/.ssh/下面 在~/.ssh/目录下共有如下文件 id_rsa.pub id_rsa_gitlab.pub id_rsa id_rsa_gitlab 第二步 配置秘钥分别读取id_rsa和id_rsa_gitlab cat id_rsa.pub cat id_rsa_gitlab.pub 将公钥分别配置到github和gitlab的个人设置里面 第三步 配置config在 ~/.ssh/目录下创建config文件 cd ~/.ssh/ vim config 输入以下配置12345678910# gitlabHost gitlab HostName gitlab.ctzcdn.com IdentityFile ~/.ssh/id_rsa_gitlab# githubhttp://zhzhzh@106.39.160.94/front/webpackDevKit.gitHost github HostName github.com IdentityFile ~/.ssh/id_rsa 第四部 使用由于之前使用gitHub时，将github的用户名，邮箱设置为了全局所以在gitlab项目中，需要另外设置用户名为gitlab的用户名和邮箱： git init git config --local user.name &quot;gitlab用户名&quot; git config --local user.emai &quot;gitlab申请邮箱&quot; 这样在gitlab项目目录下的就可以将项目远程配置给gitlab服务器了 git remote add origin http://zhzhzh@106.39.160.94/front/webpackDevKit.git 异常处理另外注意：在使用ssh连接的时候，报了一个错误： git push origin master ssh_exchange_identification: read: Connection reset by peer fatal: Could not read from remote repository. Please make sure you have the correct access rights and the repository exists. 目前还没搞清楚原因在哪里，解决办法为将连接地址改为http协议，而不是ssh协议。]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[java元注解]]></title>
    <url>%2F2016%2F12%2F06%2Fjava%2Fjava%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[元注解（修饰注解的注解） 注解 说明 参数 @interface 使用 @interface 关键字声明一个注解 @Inherited @Inherited：允许子类继承父类的注解。 @Retention 这种类型的注解会被保留到哪个阶段 @Documented 注解表明这个注解应该被 javadoc工具记录. @Target 注解的作用目标 元注解源码Target和ElementType枚举12345678910111213141516171819202122232425@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Target &#123; ElementType[] value();&#125;public enum ElementType &#123; /** Class, interface (including annotation type), or enum declaration */ TYPE, /** Field declaration (includes enum constants) */ FIELD, /** Method declaration */ METHOD, /** Parameter declaration */ PARAMETER, /** Constructor declaration */ CONSTRUCTOR, /** Local variable declaration */ LOCAL_VARIABLE, /** Annotation type declaration */ ANNOTATION_TYPE, /** Package declaration */ PACKAGE&#125; Retention注解源码和RetentionPolicy枚举1234567891011121314151617181920212223242526@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.ANNOTATION_TYPE)public @interface Retention &#123; RetentionPolicy value();&#125;public enum RetentionPolicy &#123; /** * Annotations are to be discarded by the compiler. */ SOURCE, /** * Annotations are to be recorded in the class file by the compiler * but need not be retained by the VM at run time. This is the default * behavior. */ CLASS, /** * Annotations are to be recorded in the class file by the compiler and * retained by the VM at run time, so they may be read reflectively. * * @see java.lang.reflect.AnnotatedElement */ RUNTIME&#125; 创建一个注解123456789/** * 下划线转换驼峰注解 * @version 2.0 */@Inherited @Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD)public @interface ConvertHump &#123;&#125; @CallerSensitive1234@Retention(RetentionPolicy.RUNTIME)@Target(&#123; java.lang.annotation.ElementType.METHOD &#125;)public @interface CallerSensitive &#123;&#125; 这个注解是为了堵住漏洞用的。曾经有黑客通过构造双重反射来提升权限，原理是当时反射只检查固定深度的调用者的类，看它有没有特权，例如固定看两层的调用者（getCallerClass(2)）。如果我的类本来没足够权限群访问某些信息，那我就可以通过双重反射去达到目的：反射相关的类是有很高权限的，而在 我-&gt;反射1-&gt;反射2 这样的调用链上，反射2检查权限时看到的是反射1的类，这就被欺骗了，导致安全漏洞。使用CallerSensitive后，getCallerClass不再用固定深度去寻找actual caller（“我”），而是把所有跟反射相关的接口方法都标注上CallerSensitive，搜索时凡看到该注解都直接跳过，这样就有效解决了前面举例的问题 ​]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>java</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据结构java代码实现笔记文档]]></title>
    <url>%2F2016%2F12%2F06%2Fjava%2FJava%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[单链表的反转123456789101112131415//构建单链表节点public class ListNode &#123;//元素，和下一个listnodepublic Object element;public ListNode next;//构造方法1public ListNode(Object element) &#123; this(element, null);&#125;//构造方法2public ListNode(Object element,ListNode n) &#123; this.element=element; this.next=n;&#125;&#125; 递归方法12345678910//在反转当前节点之前先反转后续节点 public static ListNode reverse1(ListNode head)&#123; if(null==head||head.getNext()==null)&#123; return head; &#125; ListNode reverseNode =reverse1(head.getNext()); head.getNext().setNext(head); head.setNext(null); return reverseNode;&#125; 非递归实现1234567891011121314151617181920212223 /** * 遍历实现* 遍历，将当前节点的下一个节点缓存后更改当前节点指针 * */ public static ListNode reverse2(ListNode head)&#123; if(null==head||head.getNext()==null)&#123; return head; &#125; ListNode pre =head; ListNode cur =head.getNext(); ListNode next; while(cur!=null)&#123; next=cur.getNext(); cur.setNext(pre); pre=cur; cur=next; &#125; //将原链表的头节点的下一个节点置为null，再将反转后的头节点赋给head head.setNext(null); head=pre; return head; &#125; 排序排序大的分类可以分为两种：内排序和外排序。在排序过程中，全部记录存放在内存，则称为内排序，如果排序过程中需要使用外存，则称为外排序。下面讲的排序都是属于内排序。 内排序有可以分为以下几类： (1)、插入排序：直接插入排序、二分法插入排序、希尔排序。 (2)、选择排序：简单选择排序、堆排序。 (3)、交换排序：冒泡排序、快速排序。 (4)、归并排序 (5)、基数排序 插入排序思想：每步将一个待排序的记录，按其顺序码大小插入到前面已经排序的字序列的合适位置，直到全部插入排序完为止。关键问题：在前面已经排好序的序列中找到合适的插入位置。方法： 直接插入排序 二分插入排序 希尔排序 ①直接插入排序（从后向前找到合适位置后插入） 1、基本思想：每步将一个待排序的记录，按其顺序码大小插入到前面已经排序的字序列的合适位置（从后向前找到合适位置后），直到全部插入排序完为止。 2、实例3、java实现​1234567891011121314151617181920212223int[] a=&#123;49,38,65,97,76,13,27,49,78,34,12,64,1&#125;; System.out.println("排序之前："); for (int i = 0; i &lt; a.length; i++) &#123; System.out.print(a[i]+" "); System.out.println(a.length+""); &#125; for(int i=1;i&lt;a.length;i++)&#123; //从第二个开始比较 int temp=a[i]; int j; //往前边遍历 for(int j=i-1;j&gt;=0;j--)&#123; if(a[j]&gt;a[i])&#123; a[j+1]=a[j]; &#125; else&#123; //跳出for break; &#125; &#125; //因为j在for的时候进行了--操作，所以在这里要进行+1 a[j+1]=temp;&#125; 4、分析 直接插入排序是稳定的排序。关于各种算法的稳定性分析可以参考http://www.cnblogs.com/Braveliu/archive/2013/01/15/2861201.html 文件初态不同时，直接插入排序所耗费的时间有很大差异。若文件初态为正序，则每个待插入的记录只需要比较一次就能够找到合适的位置插入，故算法的时间复杂度为O(n)，这时最好的情况。若初态为反序，则第i个待插入记录需要比较i+1次才能找到合适位置插入，故时间复杂度为O(n2)，这时最坏的情况。 直接插入排序的平均时间复杂度为O(n2)。 ②二分法插入排序（按二分法找到合适位置插入）1、基本思想：二分法插入排序的思想和直接插入一样，只是找合适的插入位置的方式不同，这里是按二分法找到合适的位置，可以减少比较的次数。 2、实例3、java实现 123456789101112131415161718192021222324252627public static void sort(int[] a)&#123; //循环 for(int i =0;i&lt;a.length;i++)&#123; int left=0; int temp=a[i]; int right=i-1; int mid=0; //循环，直至找到最接近a[i]的a[left] while(left&lt;=right)&#123; mid=(left+right)/2; if(temp&lt;a[mid])&#123; right=mid-1; &#125; else&#123; left=mid+1; &#125; &#125; //从a[left]到a[i-1]往右移动 for(int j=i-1;j&gt;=left;j--)&#123; a[j+1]=a[j]; &#125; //将a[i]赋值给a[left] if(left!=i)&#123; a[left]=temp; &#125; &#125; &#125; 4、分析 当然，二分法插入排序也是稳定的。 二分插入排序的比较次数与待排序记录的初始状态无关，仅依赖于记录的个数。当n较大时，比直接插入排序的最大比较次数少得多。但大于直接插入排序的最小比较次数。算法的移动次数与直接插入排序算法的相同，最坏的情况为n2/2，最好的情况为n，平均移动次数为O(n2)。 ③希尔排序1、基本思想：先取一个小于n的整数d1作为第一个增量，把文件的全部记录分成d1个组。所有距离为d1的倍数的记录放在同一个组中。先在各组内进行直接插入排序；然后，取第二个增量d2&lt; d1重复上述的分组和排序，直至所取的增量dt=1(dt&lt; dt-l&lt;… &lt; d2 &lt; d1)，即所有记录放在同一组中进行直接插入排序为止。该方法实质上是一种分组插入方法。2、实例3、java实现 12345678910111213141516171819202122232425public static void sort4(int[] a)&#123; int d=a.length; while(true)&#123; d=d/2; for(int x=0;x&lt;d;x++)&#123; for(int i=x+d;i&lt;a.length;i=i+d)&#123; //进行小组内的插入排序 int temp=a[i]; int j; for( j=i-d;j&gt;=0&amp;&amp;a[j]&gt;temp;j=j-d)&#123; a[j+d]=a[j]; &#125; a[j+d]=temp; &#125; &#125; if(d==1)&#123; break; &#125; &#125; System.out.println("排序之后："); for (int i = 0; i &lt; a.length; i++) &#123; System.out.print(a[i]+" "); &#125; &#125; 4、分析 我们知道一次插入排序是稳定的，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱，所以希尔排序是不稳定的。 希尔排序的时间性能优于直接插入排序，原因如下： （1）当文件初态基本有序时直接插入排序所需的比较和移动次数均较少。 （2）当n值较小时，n和n2的差别也较小，即直接插入排序的最好时间复杂度O(n)和最坏时间复杂度0(n2)差别不大。 （3）在希尔排序开始时增量较大，分组较多，每组的记录数目少，故各组内直接插入较快，后来增量di逐渐缩小，分组数逐渐减少，而各组的记录数目逐渐增多，但由于已经按di-1作为距离排过序，使文件较接近于有序状态，所以新的一趟排序过程也较快。 因此，希尔排序在效率上较直接插人排序有较大的改进。 希尔排序的平均时间复杂度为O(nlogn)。 选择排序思想：每趟从待排序的记录序列中选择关键字最小的记录放置到已排序表的最前位置，直到全部排完。关键问题：在剩余的待排序记录序列中找到最小关键码记录。方法： –直接选择排序 –堆排序 ①简单的选择排序 1、基本思想：在要排序的一组数中，选出最小的一个数与第一个位置的数交换；然后在剩下的数当中再找最小的与第二个位置的数交换，如此循环到倒数第二个数和最后一个数比较为止。 2、实例3、java实现​123456789101112131415public static void sort4(int[] a)&#123; for(int i=0;i&lt;a.length-1;i++)&#123; int temp=a[i]; int j; int index=i; for(j=i+1;j&lt;a.length;j++)&#123; if(a[index]&gt;a[j])&#123; //找出最小元素的下标 index=j; &#125; &#125; a[i]=a[index]; a[index]=temp; &#125;&#125; 4、分析 简单选择排序是不稳定的排序。 时间复杂度：T(n)=O(n2)。 ②堆排序 1、基本思想： 堆排序是一种树形选择排序，是对直接选择排序的有效改进。 堆的定义下：具有n个元素的序列 （h1,h2,…,hn),当且仅当满足（hi&gt;=h2i,hi&gt;=2i+1）或（hi&lt;=h2i,hi&lt;=2i+1） (i=1,2,…,n/2)时称之为堆。在这里只讨论满足前者条件的堆。由堆的定义可以看出，堆顶元素（即第一个元素）必为最大项（大顶堆）。完全二 叉树可以很直观地表示堆的结构。堆顶为根，其它为左子树、右子树。 思想:初始时把要排序的数的序列看作是一棵顺序存储的二叉树，调整它们的存储序，使之成为一个 堆，这时堆的根节点的数最大。然后将根节点与堆的最后一个节点交换。然后对前面(n-1)个数重新调整使之成为堆。依此类推，直到只有两个节点的堆，并对 它们作交换，最后得到有n个节点的有序序列。从算法描述来看，堆排序需要两个过程，一是建立堆，二是堆顶与堆的最后一个元素交换位置。所以堆排序有两个函数组成。一是建堆的渗透函数，二是反复调用渗透函数实现排序的函数。 2、实例 初始序列：46,79,56,38,40,84 建堆：交换，从堆中踢出最大数依次类推：最后堆中剩余的最后两个结点交换，踢出一个，排序完成。 3、java实现 1234567891011121314151617181920212223242526272829303132333435363738394041424344public static void heapSort(int[] a )&#123; int arrayLength=a.length; for(int i=0;i&lt;arrayLength-1;i--)&#123; buildMaxHeap(a,arrayLength-1-i); //交换堆顶和最后一个元素 swap(a,0,arrayLength-1-i); &#125;&#125; //对data数组从0到lastIndex建大顶堆 public static void buildMaxHeap(int[] data, int lastIndex)&#123; //从lastIndex处节点（最后一个节点）的父节点开始 for(int i=(lastIndex-1)/2;i&gt;=0;i--)&#123; //k保存正在判断的节点 int k=i; //如果当前k节点的子节点存在 while(k*2+1&lt;=lastIndex)&#123; //k节点的左子节点的索引 int biggerIndex=2*k+1; //如果biggerIndex小于lastIndex，即biggerIndex+1代表的k节点的右子节点存在 if(biggerIndex&lt;lastIndex)&#123; //若果右子节点的值较大 if(data[biggerIndex]&lt;data[biggerIndex+1])&#123; //biggerIndex总是记录较大子节点的索引 biggerIndex++; &#125; &#125; //如果k节点的值小于其较大的子节点的值 if(data[k]&lt;data[biggerIndex])&#123; //交换他们 swap(data,k,biggerIndex); //将biggerIndex赋予k，开始while循环的下一次循环，重新保证k节点的值大于其左右子节点的值 k=biggerIndex; &#125;else&#123; break; &#125; &#125; &#125; &#125; //交换 private static void swap(int[] data, int i, int j) &#123; int tmp=data[i]; data[i]=data[j]; data[j]=tmp; &#125; 4、分析 堆排序也是一种不稳定的排序算法。 堆排序优于简单选择排序的原因： 直接选择排序中，为了从R[1..n]中选出关键字最小的记录，必须进行n-1次比较，然后在R[2..n]中选出关键字最小的记录，又需要做n-2次比较。事实上，后面的n-2次比较中，有许多比较可能在前面的n-1次比较中已经做过，但由于前一趟排序时未保留这些比较结果，所以后一趟排序时又重复执行了这些比较操作。 堆排序可通过树形结构保存部分比较结果，可减少比较次数。 堆排序的最坏时间复杂度为O(nlogn)。堆序的平均性能较接近于最坏性能。由于建初始堆所需的比较次数较多，所以堆排序不适宜于记录数较少的文件。 交换排序①冒泡排序 1、基本思想：在要排序的一组数中，对当前还未排好序的范围内的全部数，自上而下对相邻的两个数依次进行比较和调整，让较大的数往下沉，较小的往上冒。即：每当两相邻的数比较后发现它们的排序与排序要求相反时，就将它们互换。 2、实例3、java实现​123456789101112131415public static void sort5(int[] a)&#123; for(int i=0;i&lt;a.length;i++)&#123; for(int j=0;j&lt;a.length-1-i;j++)&#123; if(a[j]&gt;a[j+1])&#123; int temp=a[j]; a[j]=a[j+1]; a[j+1]=temp; &#125; &#125; &#125; System.out.println("冒泡排序之后："); for (int i = 0; i &lt; a.length; i++) &#123; System.out.print(a[i]+" "); &#125;&#125; 4、分析 冒泡排序是一种稳定的排序方法。 若文件初状为正序，则一趟起泡就可完成排序，排序码的比较次数为n-1，且没有记录移动，时间复杂度是O(n)若文件初态为逆序，则需要n-1趟起泡，每趟进行n-i次排序码的比较，且每次比较都移动三次，比较和移动次数均达到最大值∶O(n2)起泡排序平均时间复杂度为O(n2) ②快速排序 1、基本思想：选择一个基准元素,通常选择第一个元素或者最后一个元素,通过一趟扫描，将待排序列分成两部分,一部分比基准元素小,一部分大于等于基准元素,此时基准元素在其排好序后的正确位置,然后再用同样的方法递归地排序划分的两部分。 2、实例3、java实现 1234567891011121314151617181920212223242526272829303132333435 private static void quicksort(int[] a) &#123; if(a.length&gt;0)&#123; quickSort(a,0,a.length-1); &#125; System.out.println(""); System.out.println("快速排序之后："); for (int i = 0; i &lt; a.length; i++) &#123; System.out.print(a[i]+" "); &#125; &#125; //递归 private static void quickSort(int[] a, int low, int high) &#123; if(low&lt;high)&#123; //如果不加这个判断递归会无法退出导致堆栈溢出异常 int middle = getMiddle(a,low,high); quickSort(a, 0, middle-1); quickSort(a, middle+1, high); &#125; &#125; private static int getMiddle(int[] a, int low, int high) &#123; int temp = a[low];//基准元素 while(low&lt;high)&#123; //找到比基准元素小的元素位置 while(low&lt;high &amp;&amp; a[high]&gt;=temp)&#123; high--; &#125; a[low] = a[high]; while(low&lt;high &amp;&amp; a[low]&lt;=temp)&#123; low++; &#125; a[high] = a[low]; &#125; a[low] = temp; return low; &#125; 4、分析 快速排序是不稳定的排序。 快速排序的时间复杂度为O(nlogn)。 当n较大时使用快排比较好，当序列基本有序时用快排反而不好。 归并排序 1、基本思想:归并（Merge）排序法是将两个（或两个以上）有序表合并成一个新的有序表，即把待排序序列分为若干个子序列，每个子序列是有序的。然后再把有序子序列合并为整体有序序列。 2、实例3、java实现 123456789101112131415161718192021222324252627282930313233343536private static void mergeSort(int[] a, int left, int right) &#123; if(left&lt;right)&#123; int middle = (left+right)/2; //对左边进行递归 mergeSort(a, left, middle); //对右边进行递归 mergeSort(a, middle+1, right); //合并 merge(a,left,middle,right); &#125;&#125;private static void merge(int[] a, int left, int middle, int right) &#123; int[] tmpArr = new int[a.length]; int mid = middle+1; //右边的起始位置 int tmp = left; int third = left; while(left&lt;=middle &amp;&amp; mid&lt;=right)&#123; //从两个数组中选取较小的数放入中间数组 if(a[left]&lt;=a[mid])&#123; tmpArr[third++] = a[left++]; &#125;else&#123; tmpArr[third++] = a[mid++]; &#125; &#125; //将剩余的部分放入中间数组 while(left&lt;=middle)&#123; tmpArr[third++] = a[left++]; &#125; while(mid&lt;=right)&#123; tmpArr[third++] = a[mid++]; &#125; //将中间数组复制回原数组 while(tmp&lt;=right)&#123; a[tmp] = tmpArr[tmp++]; &#125;&#125; 4、分析 归并排序是稳定的排序方法。 归并排序的时间复杂度为O(nlogn)。 速度仅次于快速排序，为稳定排序算法，一般用于对总体无序，但是各子项相对有序的数列。 基数排序 1、基本思想：将所有待比较数值（正整数）统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始，依次进行一次排序。这样从最低位排序一直到最高位排序完成以后,数列就变成一个有序序列。 2、实例3、java实现​ 1234567891011121314151617181920212223242526272829303132333435363738394041private static void sort(int[] array) &#123; //找到最大数，确定要排序几趟 int max = 0; for (int i = 0; i &lt; array.length; i++) &#123; if(max&lt;array[i])&#123; max = array[i]; &#125; &#125; //判断位数 int times = 0; while(max&gt;0)&#123; max = max/10; times++; &#125; //建立十个队列 List&lt;ArrayList&gt; queue = new ArrayList&lt;ArrayList&gt;(); for (int i = 0; i &lt; 10; i++) &#123; ArrayList queue1 = new ArrayList(); queue.add(queue1); &#125; //进行times次分配和收集 for (int i = 0; i &lt; times; i++) &#123; //分配 for (int j = 0; j &lt; array.length; j++) &#123; int x = array[j]%(int)Math.pow(10, i+1)/(int)Math.pow(10, i); ArrayList queue2 = queue.get(x); queue2.add(array[j]); queue.set(x,queue2); &#125; //收集 int count = 0; for (int j = 0; j &lt; 10; j++) &#123; while(queue.get(j).size()&gt;0)&#123; ArrayList&lt;Integer&gt; queue3 = queue.get(j); array[count] = queue3.get(0); queue3.remove(0); count++; &#125; &#125; &#125;&#125; 分析 基数排序是稳定的排序算法。 基数排序的时间复杂度为O(d(n+r)),d为位数，r为基数。总结： 稳定性: 稳定：冒泡排序、插入排序、归并排序和基数排序 不稳定：选择排序、快速排序、希尔排序、堆排序 平均时间复杂度 O(n^2):直接插入排序，简单选择排序，冒泡排序。 在数据规模较小时（9W内），直接插入排序，简单选择排序差不多。当数据较大时，冒泡排序算法的时间代价最高。性能为O(n^2)的算法基本上是相邻元素进行比较，基本上都是稳定的。 O(nlogn):快速排序，归并排序，希尔排序，堆排序。 其中，快排是最好的， 其次是归并和希尔，堆排序在数据量很大时效果明显。 排序算法的选择 1.数据规模较小​ 待排序列基本序的情况下，可以选择直接插入排序； ​ 对稳定性不作要求宜用简单选择排序，对稳定性有要求宜用插入或冒泡 2.数据规模不是很大​ 完全可以用内存空间，序列杂乱无序，对稳定性没有要求，快速排序，此时要付出log（N）的额外空间。 ​ 序列本身可能有序，对稳定性有要求，空间允许下，宜用归并排序 3.数据规模很大对稳定性有求，则可考虑归并排序。 对稳定性没要求，宜用堆排序 4.序列初始基本有序（正序），宜用直接插入，冒泡参考资料: 代码实现参考：http://blog.csdn.net/without0815/article/details/7697916算法性能分析参考：http://gengning938.blog.163.com/blog/static/128225381201141121326346/ 二叉树构建二叉树123456789public class TreeNode &#123; int val; TreeNode left; TreeNode right; public TreeNode(int val) &#123; this.val = val; &#125; &#125; 求二叉树中的节点个数递归实现1234567 public static int getNodeNumRec(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; else &#123; return getNodeNumRec(root.left) + getNodeNumRec(root.right) + 1; &#125; &#125; 迭代实现12345678910111213141516171819202122 public static int getNodeNum(TreeNode root) &#123; if(root == null)&#123; return 0; &#125; int count = 1; Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;(); queue.add(root); while(!queue.isEmpty())&#123; TreeNode cur = queue.remove(); // 从队头位置移除 if(cur.left != null)&#123; // 如果有左孩子，加到队尾 queue.add(cur.left); count++; &#125; if(cur.right != null)&#123; // 如果有右孩子，加到队尾 queue.add(cur.right); count++; &#125; &#125; return count; &#125; 求树的深度递归解法： O(n)12345678910111213 * 求二叉树的深度（高度） 递归解法： O(n) * （1）如果二叉树为空，二叉树的深度为0 * （2）如果二叉树不为空，二叉树的深度 = max(左子树深度， 右子树深度) + 1 */ public static int getDepthRec(TreeNode root) &#123; if (root == null) &#123; return 0; &#125; int leftDepth = getDepthRec(root.left); int rightDepth = getDepthRec(root.right); return Math.max(leftDepth, rightDepth) + 1; &#125; 迭代解法： O(n)基本思想同LevelOrderTraversal，还是用一个Queue 123456789101112131415161718192021222324252627282930313233 public static int getDepth(TreeNode root) &#123; if(root == null)&#123; return 0; &#125; int depth = 0; // 深度 int currentLevelNodes = 1; // 当前Level，node的数量 int nextLevelNodes = 0; // 下一层Level，node的数量 LinkedList&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;(); queue.add(root); while( !queue.isEmpty() )&#123; TreeNode cur = queue.remove(); // 从队头位置移除 currentLevelNodes--; // 减少当前Level node的数量 if(cur.left != null)&#123; // 如果有左孩子，加到队尾 queue.add(cur.left); nextLevelNodes++; // 并增加下一层Level node的数量 &#125; if(cur.right != null)&#123; // 如果有右孩子，加到队尾 queue.add(cur.right); nextLevelNodes++; &#125; if(currentLevelNodes == 0)&#123; // 说明已经遍历完当前层的所有节点 depth++; // 增加高度 currentLevelNodes = nextLevelNodes; // 初始化下一层的遍历 nextLevelNodes = 0; &#125; &#125; return depth; &#125; 二叉树的遍历前序遍历，中序遍历，后序遍历 前序遍历递归解法1234567891011121314151617181920212223 /** * 前序遍历，中序遍历，后序遍历 前序遍历递归解法**： * （1）如果二叉树为空，空操作 * （2）如果二叉树不为空，访问根节点，前序遍历左子树，前序遍历右子树 */ public static void preorderTraversalRec(TreeNode root) &#123; if (root == null) &#123; return; &#125; //前序 System.out.print(root.val + " "); preorderTraversalRec(root.left); preorderTraversalRec(root.right); //中序 preorderTraversalRec(root.left); System.out.print(root.val + " "); preorderTraversalRec(root.right); //后序 preorderTraversalRec(root.left); preorderTraversalRec(root.right); System.out.print(root.val + " ");&#125; 前序迭代解法1234567891011121314151617181920212223242526 /** * **前序遍历迭代解法**：用一个辅助stack，总是把右孩子放进栈 * http://www.youtube.com/watch?v=uPTCbdHSFg4 */ public static void preorderTraversal(TreeNode root) &#123; if(root == null)&#123; return; &#125; Stack&lt;TreeNode&gt; stack = new Stack&lt;TreeNode&gt;(); // 辅助stack stack.push(root); while( !stack.isEmpty() )&#123; TreeNode cur = stack.pop(); // 出栈栈顶元素 System.out.print(cur.val + " "); // 关键点：要先压入右孩子，再压入左孩子，这样在出栈时会先打印左孩子再打印右孩子 if(cur.right != null)&#123; stack.push(cur.right); &#125; if(cur.left != null)&#123; stack.push(cur.left); &#125; &#125; &#125;]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>java</tag>
        <tag>数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据库基础]]></title>
    <url>%2F2016%2F11%2F05%2F%E6%95%B0%E6%8D%AE%E5%BA%93%2F%E6%95%B0%E6%8D%AE%E5%BA%93%E9%9D%A2%E8%AF%95%E8%B5%84%E6%96%99%2F</url>
    <content type="text"><![CDATA[数据库三范式是什么? 1第一范式就是无重复的列。 2第二范式就是无重复的行 第二范式（2NF）是在第一范式（1NF）的基础上建立起来的，即满足第二范式（2NF）必须先满足第一范式（1NF）。第二范式（2NF）要求数据库表中的每个实例或行必须可以被唯一地区分。为实现区分通常需要为表加上一个列，以存储各个实例的唯一标识。 员工信息表中加上了员工编号（emp_id）列，因为每个员工的员工编号是唯一的，因此每个员工可以被唯一区分。这个唯一属性列被称为主关键字或主键、主码。第二范式（2NF）要求实体的属性完全依赖于主关键字。所谓完全依赖是指不能存在仅依赖主关键字一部分的属性，如果存在，那么这个属性和主关键字的这一部分应该分离出来形成一个新的实体，新实体与原实体之间是一对多的关系。为实现区分通常需要为表加上一个列，以存储各个实例的唯一标识。简而言之，第二范式就是非主属性非部分依赖于主关键字。 3第三范式就是引用别的表的字段时，不能出现非主键字段。第三范式（3NF） 满足第三范式（3NF）必须先满足第二范式（2NF）。简而言之，第三范式（3NF）要求一个数据库表中不包含已在其它表中已包含的非主关键字信息。例如，存在一个部门信息表，其中每个部门有部门编号（dept_id）、部门名称、部门简介等信息。那么在图3-2的员工信息表中列出部门编号后就不能再将部门名称、部门简介等与部门有关的信息再加入员工信息表中。如果不存在部门信息表，则根据第三范式（3NF）也应该构建它，否则就会有大量的数据冗余。简而言之，第三范式就是属性不依赖于其它非主属性。 数据库表连接连接一共分为内连接、外连接和交叉连接 内连接内连接(INNER JOIN)使用比较运算符进行表间某(些)列数据的比较操作，并列出这些表中与连接条件相匹配的数据行。根据所使用的比较方式不同，内连接又分为等值连接、自然连接和不等连接三种。 内连接分三种： 等值连接等值连接：在连接条件中使用等于号(=)运算符比较被连接列的列值，其查询结果中列出被连接表中的所有列，包括其中的重复列。 不等连接不等连接：在连接条件使用除等于运算符以外的其它比较运算符比较被连接的列的列值。这些运算符包括&gt;、&gt;=、、!。 自然连接自然连接：在连接条件中使用等于(=)运算符比较被连接列的列值，但它使用选择列表指出查询结果集合中所包括的列，并删除连接表中的重复列。 等值连接与自然连接的区别：1）等值连接中不要求相等属性值的属性名相同，而自然连接要求相等属性值的属性名必须相同，即两关系只有在同名属性才能进行自然连接。2）等值连接不将重复属性去掉，而自然连接去掉重复属性，也可以说，自然连接是去掉重复列的等值连接。 外连接外连接分为左外连接(LEFT OUTER JOIN或LEFT JOIN)、右外连接(RIGHT OUTER JOIN或RIGHT JOIN)和全外连接(FULL OUTER JOIN或FULL JOIN)三种。内连接查询时，返回查询结果集合中的仅是符合查询条件( WHERE 搜索条件或 HAVING 条件)和连接条件的行。而采用外连接时，它返回到查询结果集合中的不仅包含符合连接条件的行，而且还包括左表(左外连接时)、右表(右外连接时)或两个边接表(全外连接)中的所有数据行。 如下面使用左外连接将论坛内容和作者信息连接起来：代码:SELECT a.,b. FROM luntan as a LEFT JOIN usertable as bON a.username=b.username下面使用全外连接将city表中的所有作者以及user表中的所有作者，以及他们所在的城市：代码:SELECT a.,b.FROM city as a FULL OUTER JOIN user as bON a.username=b.username 交叉连接交叉连接不带WHERE 子句，它返回被连接的两个表所有数据行的笛卡尔积，返回到结果集合中的数据行数等于第一个表中符合查询条件的数据行数乘以第二个表中符合查询条件的数据行数。例，titles表中有6类图书，而publishers表中有8家出版社，则下列交叉连接检索到的记录数将等于6*8=48行。代码:SELECT type,pub_nameFROM titles CROSS JOIN publishersORDER BY type Group by与having理解group by 有一个原则,就是 select 后面的所有列中,没有使用聚合函数的列,必须出现在 group by 后面（重要） having子句与where有相似之处但也有区别,都是设定条件的语句。在查询过程中聚合语句(sum,min,max,avg,count)要比having子句优先执行.而where子句在查询过程中执行优先级别优先于聚合语句(sum,min,max,avg,count)。 结论：1.WHERE 子句用来筛选 FROM 子句中指定的操作所产生的行。2.GROUP BY 子句用来分组 WHERE 子句的输出。3.HAVING 子句用来从分组的结果中筛选行。]]></content>
      <categories>
        <category>coding</category>
      </categories>
      <tags>
        <tag>数据库</tag>
        <tag>mysql</tag>
      </tags>
  </entry>
</search>
